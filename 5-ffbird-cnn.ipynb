{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Workbook 5 - Recognising birds from FreeField1010 recordings using a Convolutional Neural Network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous 4 workbooks have been processing audio the UrbanSound8K data set, this was chosen because it provided a large and varied set of samples, belonging to just 10 classes, which made it an ideal basis for developing and testing a general audio classifier. \n",
    "\n",
    "As the goal of this project is to recognise birdsong, the next logical step is to try it with actual recordings of birds. Unfortunately it seems difficult to find an equivalent of the UrbanSound8k data for birds, i.e. one where the recordings are labelled with the bird species, but I did find some interesting data sets with binary labels at http://machine-listening.eecs.qmul.ac.uk/bird-audio-detection-challenge/\n",
    "\n",
    "The binary labels are indicate that a human listener has stated that either they believe a bird is present, or that no birds are present. No species information is included, so the goal here is bird detection rather than identification, i.e. to find segments of 24-hour automated field recordings that might have interesting content, which can be forwarded to human experts who will identify what might be present.\n",
    "\n",
    "So here I'm going to adapt the CNN produced in workbook 4, and train it on the FreeField1010 data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the feature extraction code, it uses a similar process to that described in workbook 4. You'll only need to run this once, to obtain the feature data from the raw recordings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def windows(data, window_size):\n",
    "    start = 0\n",
    "    while start < len(data):\n",
    "        yield start, start + window_size\n",
    "        start += (window_size / 2)\n",
    "\n",
    "def extract_features(wav_dir, sub_dirs, file_ext=\"*.wav\",bands = 60, frames = 41, label_dict={}):\n",
    "    window_size = 512 * (frames - 1)\n",
    "    log_specgrams = []\n",
    "    labels = []\n",
    "    for l, sub_dir in enumerate(sub_dirs):\n",
    "        for i, fn in enumerate(glob.glob(os.path.join(wav_dir, sub_dir, file_ext))):\n",
    "            #print i\n",
    "            sound_clip,s = librosa.load(fn)\n",
    "            \n",
    "            idstr = os.path.basename(fn).split('.wav')[0]\n",
    "            if idstr not in label_dict.keys():\n",
    "                print \"No such entry \", idstr, 'skipping'\n",
    "                continue\n",
    "                \n",
    "            label = label_dict[idstr]    \n",
    "            \n",
    "            for (start,end) in windows(sound_clip,window_size):\n",
    "                if(len(sound_clip[start:end]) == window_size):\n",
    "                    signal = sound_clip[start:end]\n",
    "                    melspec = librosa.feature.melspectrogram(signal, n_mels = bands)\n",
    "                    logspec = librosa.logamplitude(melspec)\n",
    "                    logspec = logspec.T.flatten()[:, np.newaxis].T\n",
    "                    log_specgrams.append(logspec)\n",
    "                    labels.append(label)\n",
    "\n",
    "    log_specgrams = np.asarray(log_specgrams).reshape(len(log_specgrams),bands,frames,1)\n",
    "    features = np.concatenate((log_specgrams, np.zeros(np.shape(log_specgrams))), axis = 3)\n",
    "    for i in range(len(features)):\n",
    "        features[i, :, :, 1] = librosa.feature.delta(features[i, :, :, 0])\n",
    "    \n",
    "    return np.array(features), np.array(labels,dtype = np.int)\n",
    "\n",
    "def one_hot_encode(labels):\n",
    "    n_labels = len(labels)\n",
    "    n_unique_labels = len(np.unique(labels))\n",
    "    one_hot_encode = np.zeros((n_labels,n_unique_labels))\n",
    "    one_hot_encode[np.arange(n_labels), labels] = 1\n",
    "    return one_hot_encode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code extracts features from the raw FreeField1010 recordings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entries: 7690\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def assure_path_exists(path):\n",
    "    mydir = os.path.join(os.getcwd(), path)\n",
    "    if not os.path.exists(mydir):\n",
    "        os.makedirs(mydir)\n",
    "        \n",
    "def is_folded(files_dir, num_folds=10):\n",
    "    \"\"\"Check if files are in folders named 'fold1', 'fold2', etc.\"\"\"\n",
    "    res = True\n",
    "    range_folds = map(lambda x: 'fold' + str(x), range(0, num_folds))\n",
    "    root, dirs, files = next(os.walk(files_dir))\n",
    "    for i, name in enumerate(sorted(dirs)):\n",
    "        if name != range_folds[i]:\n",
    "            res=False\n",
    "            break\n",
    "    return res\n",
    "\n",
    "\n",
    "def make_folds(files_dir, num_folds=10, prefix='fold', ext='.wav'):\n",
    "    \"\"\"Move files in 1st level of directory randomly into sub-folders named 'fold1', 'fold2', etc.\"\"\"\n",
    "    regex_str = os.path.join(os.getcwd(), files_dir,'*'+ext)\n",
    "    filenames = glob.glob(regex_str)\n",
    "    random_indices = range(len(filenames))\n",
    "    shuffle(random_indices)\n",
    "    fold_size = int(len(filenames) / num_folds)\n",
    "    \n",
    "    for fold_i in range(num_folds):\n",
    "        new_fold_dir_name = '{}{}'.format(prefix, fold_i)\n",
    "        assure_path_exists(os.path.join(files_dir, new_fold_dir_name))\n",
    "        start_i = fold_i*fold_size\n",
    "        end_i = (fold_i+1)*fold_size if fold_i < num_folds else None\n",
    "        i_subset = random_indices[start_i:end_i]\n",
    "        for file_i in i_subset:\n",
    "            fn = filenames[file_i]\n",
    "            new_fn = os.path.join(os.path.dirname(fn), new_fold_dir_name)\n",
    "            os.rename(filename, new_fn)\n",
    "            # print('moving {} \\n to {}'.format(fn, new_fn))\n",
    "\n",
    "# use this to process the audio files into numpy arrays\n",
    "def save_folds(data_dir, num_folds=10):\n",
    "    pool=Pool(3)\n",
    "    pool.map(save_fold, range(1, num_folds))\n",
    "    \n",
    "def save_fold(k):\n",
    "    fold_name = 'fold' + str(k)\n",
    "    print \"\\nSaving \" + fold_name\n",
    "    features, labels = extract_features(wav_dir, [fold_name], label_dict=label_dict)\n",
    "    labels = one_hot_encode(labels)\n",
    "\n",
    "    print \"Features of\", fold_name , \" = \", features.shape\n",
    "    print \"Labels of\", fold_name , \" = \", labels.shape\n",
    "\n",
    "    feature_file = os.path.join(np_dir, fold_name + '_x.npy')\n",
    "    labels_file = os.path.join(np_dir, fold_name + '_y.npy')\n",
    "    np.save(feature_file, features)\n",
    "    print \"Saved \" + feature_file\n",
    "    np.save(labels_file, labels)\n",
    "    print \"Saved \" + labels_file\n",
    "\n",
    "\n",
    "# create a dictionary from the labels file\n",
    "from numpy import loadtxt\n",
    "\n",
    "data_dir = \"data/ffbird-np-cnn\"\n",
    "\n",
    "np_dir = os.path.join(data_dir, 'np') \n",
    "assure_path_exists(np_dir)\n",
    "\n",
    "wav_dir = os.path.join(data_dir, 'wav')\n",
    "assure_path_exists(wav_dir)\n",
    "\n",
    "filename = os.path.join(data_dir, 'ff1010bird_metadata.csv')\n",
    "lines = np.genfromtxt(filename, delimiter=\",\", skip_header=1, dtype=None)\n",
    "label_dict = dict()\n",
    "for i in range(len(lines)):\n",
    "    label_dict[str(lines[i][0])] = lines[i][1]\n",
    "\n",
    "print \"Entries:\", len(label_dict) \n",
    "# # update and uncomment the following lines if you want to run feature extraction for yourself   \n",
    "# assure_path_exists(data_dir)\n",
    "# if not is_folded(wav_dir):\n",
    "#     make_folds(wav_dir)\n",
    "# save_folds(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload Extracted Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold1 features:  (15380, 60, 41, 2)\n",
      "fold2 features:  (15380, 60, 41, 2)\n",
      "train_x:  (30760, 60, 41, 2)\n",
      "2 train_y:  (30760, 2)\n",
      "1 train_y:  (30760, 1)\n",
      "fold8 features:  (15380, 60, 41, 2)\n",
      "valid_x:  (15380, 60, 41, 2)\n",
      "valid_y:  (15380, 1)\n",
      "fold7 features:  (15380, 60, 41, 2)\n",
      "test_x: (15380, 60, 41, 2)\n",
      "test_y: (15380, 1)\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "# this is used to load the folds incrementally\n",
    "data_dir = \"data/ffbird-np-cnn/np\"\n",
    "\n",
    "def load_folds(folds):\n",
    "    subsequent_fold = False\n",
    "    for k in range(len(folds)):\n",
    "        fold_name = 'fold' + str(folds[k])\n",
    "        feature_file = os.path.join(data_dir, fold_name + '_x.npy')\n",
    "        labels_file = os.path.join(data_dir, fold_name + '_y.npy')\n",
    "        loaded_features = np.load(feature_file)\n",
    "        loaded_labels = np.load(labels_file)\n",
    "        print fold_name, \"features: \", loaded_features.shape\n",
    "\n",
    "        if subsequent_fold:\n",
    "            features = np.concatenate((features, loaded_features))\n",
    "            labels = np.concatenate((labels, loaded_labels))\n",
    "        else:\n",
    "            features = loaded_features\n",
    "            labels = loaded_labels\n",
    "            subsequent_fold = True\n",
    "        \n",
    "    return features, labels\n",
    "\n",
    "train_x, train_y = load_folds([1,2])\n",
    "print \"train_x: \", train_x.shape\n",
    "print \"2 train_y: \", train_y.shape\n",
    "\n",
    "train_y = scipy.delete(train_y, 1, 1) \n",
    "print \"1 train_y: \", train_y.shape\n",
    "\n",
    "valid_x, valid_y = load_folds([8])\n",
    "valid_y = scipy.delete(valid_y, 1, 1) \n",
    "print \"valid_x: \", valid_x.shape\n",
    "print \"valid_y: \", valid_y.shape\n",
    "\n",
    "test_x, test_y = load_folds([7])\n",
    "test_y = scipy.delete(test_y, 1, 1) \n",
    "print \"test_x:\", test_x.shape\n",
    "print \"test_y:\", test_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Convolutional Neural Network with Keras and TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: 1\n",
      "Feature size: 2460\n"
     ]
    }
   ],
   "source": [
    "frames = 41\n",
    "bands = 60\n",
    "\n",
    "feature_size = bands * frames #60x41\n",
    "num_labels = test_y.shape[1]\n",
    "num_channels = 2\n",
    "\n",
    "print \"Labels:\", num_labels\n",
    "print \"Feature size:\", feature_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import Adam, Adagrad, SGD\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import np_utils\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def evaluate(model):\n",
    "    y_prob = model.predict_proba(test_x, verbose=0)\n",
    "    y_pred = model.predict_classes(test_x)\n",
    "    y_true = np.argmax(test_y, 1)\n",
    "\n",
    "    roc = roc_auc_score(test_y, y_prob)\n",
    "    print \"ROC:\",  round(roc,3)\n",
    "\n",
    "    # evaluate the model\n",
    "    score, accuracy = model.evaluate(test_x, test_y, batch_size=32)\n",
    "    print(\"Accuracy = {:.2f}\".format(accuracy))\n",
    "    \n",
    "    return roc, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# implements CNN described in https://arxiv.org/pdf/1608.04363.pdf\n",
    "\n",
    "def build_model():\n",
    "    \n",
    "    model = Sequential()\n",
    "    # input: 60x41 data frames with 2 channels => (60,41,2) tensors\n",
    "\n",
    "    # filters of size 3x3 - paper describes using 5x5, but their input data is 128x128\n",
    "    f_size = 3\n",
    "\n",
    "    # Layer 1 - 24 filters with a receptive field of (f,f), i.e. W has the\n",
    "    # shape (24,1,f,f).  This is followed by (4,2) max-pooling over the last\n",
    "    # two dimensions and a ReLU activation function\n",
    "    model.add(Convolution2D(24, f_size, f_size, border_mode='same', input_shape=(bands, frames, num_channels)))\n",
    "    model.add(MaxPooling2D(pool_size=(4, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # Layer 2 - 48 filters with a receptive field of (f,f), i.e. W has the \n",
    "    # shape (48, 24, f, f). Like L1 this is followed by (4,2) max-pooling \n",
    "    # and a ReLU activation function.\n",
    "    model.add(Convolution2D(48, f_size, f_size, border_mode='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(4, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # Layer 3 - 48 filters with a receptive field of (f,f), i.e. W has the\n",
    "    # shape (48, 48, f, f). This is followed by a ReLU but no pooling.\n",
    "    model.add(Convolution2D(48, f_size, f_size, border_mode='valid'))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # flatten output into a single dimension, let Keras do shape inference\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Layer 4 - a fully connected NN layer of 64 hidden units, L2 penalty of 0.001\n",
    "    model.add(Dense(64, W_regularizer=l2(0.001)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # Layer 5 - an output layer with one output unit per class, with L2 penalty, \n",
    "    # followed by a softmax activation function\n",
    "    model.add(Dense(num_labels, W_regularizer=l2(0.001)))\n",
    "    model.add(Dropout(0.5))\n",
    "    # softmax on single output will always normalise the value to 1.0, so need sigmoid\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    # create an optimiser\n",
    "    # adagrad = Adagrad(lr=0.01, epsilon=1e-08, decay=0.0)\n",
    "    sgd = SGD(lr=0.001, momentum=0.9, decay=0.0, nesterov=True)\n",
    "\n",
    "    # compile and fit model, reduce epochs if you want a result faster\n",
    "    # the validation set is used to identify parameter settings (epoch) that achieves \n",
    "    # the highest classification accuracy (note binary rather than categorial crossentropy)\n",
    "    model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=sgd)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leonmak/.virtualenvs/keras-tf2/lib/python2.7/site-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), padding=\"same\", input_shape=(60, 41, 2...)`\n",
      "  \n",
      "/Users/leonmak/.virtualenvs/keras-tf2/lib/python2.7/site-packages/ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(48, (3, 3), padding=\"same\")`\n",
      "/Users/leonmak/.virtualenvs/keras-tf2/lib/python2.7/site-packages/ipykernel_launcher.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(48, (3, 3), padding=\"valid\")`\n",
      "/Users/leonmak/.virtualenvs/keras-tf2/lib/python2.7/site-packages/ipykernel_launcher.py:34: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(64, kernel_regularizer=<keras.reg...)`\n",
      "/Users/leonmak/.virtualenvs/keras-tf2/lib/python2.7/site-packages/ipykernel_launcher.py:40: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, kernel_regularizer=<keras.reg...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Train on 30760 samples, validate on 15380 samples\n",
      "Epoch 1/15\n",
      "30760/30760 [==============================] - 81s 3ms/step - loss: 0.7580 - acc: 0.4948 - val_loss: 0.6757 - val_acc: 0.7415\n",
      "Epoch 2/15\n",
      "30760/30760 [==============================] - 82s 3ms/step - loss: 0.7261 - acc: 0.4976 - val_loss: 0.6590 - val_acc: 0.7440\n",
      "Epoch 3/15\n",
      "30760/30760 [==============================] - 73s 2ms/step - loss: 0.7201 - acc: 0.4987 - val_loss: 0.6790 - val_acc: 0.7527\n",
      "Evaluating model...\n",
      "15380/15380 [==============================] - 14s 889us/step\n",
      "ROC: 0.691\n",
      "15380/15380 [==============================] - 16s 1ms/step\n",
      "Accuracy = 0.76\n",
      "R.O.C: 0.691\n",
      "Accuracy: 0.76\n"
     ]
    }
   ],
   "source": [
    "# the ModelCheckpoint callback automatically saves the current model's weights to a file whenever the validation accuracy improves\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=1, verbose=0, mode='auto')\n",
    "\n",
    "print(\"Building model...\")\n",
    "model = build_model()\n",
    "\n",
    "# now fit the model to the training data, evaluating loss against the validation data\n",
    "print(\"Training model...\")\n",
    "model.fit(train_x, train_y, validation_data=(valid_x, valid_y), callbacks=[earlystop], batch_size=128, nb_epoch=15)\n",
    "        \n",
    "# now evaluate the trained model against the unseen test data\n",
    "print(\"Evaluating model...\")\n",
    "roc, acc = evaluate(model)\n",
    "       \n",
    "print 'R.O.C:', round(roc, 3)\n",
    "print 'Accuracy:', round(acc, 3)\n",
    "\n",
    "# best ROC (2 folds FF) = 0.69, acc = 0.77\n",
    "# best ROC (all 6 folds FF set only) = 0.73\n",
    "# best ROC (2 sets) = 0.869, acc=0.79 (Adagrad batch=128, patience=2) 50 epochs\n",
    "# best ROC (2 sets) = 0.87 (SGD batch=128, nesterov, momentum=0.9, lr-0.001) 50 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting even better results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "There is another set of field recordings available from http://machine-listening.eecs.qmul.ac.uk/bird-audio-detection-challenge/ - the Warblr data set. By combining both the FreeField1010 and Warblr data sets I was able to obtain even better results, an F-score accuracy of 0.87, this however took considerable processing on a powerful cloud computing instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "keras-tf2",
   "language": "python",
   "name": "keras-tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
